{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Answer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd5781d8-3027-42d9-9778-f5d6b4a6e15d"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-24 16:09:04--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  78.9MB/s    in 1.1s    \n",
            "\n",
            "2019-12-24 16:09:05 (78.9 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "88407efa-4450-476e-a430-d1e70712e62e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "229618bf-9e0a-494a-945f-90dbbb760ee1"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "8d42eb15-c554-4d6f-d5ac-8b3542261149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-24 16:10:31--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.128, 2607:f8b0:4001:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  46.7MB/s    in 3.1s    \n",
            "\n",
            "2019-12-24 16:10:34 (46.7 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-12-24 16:10:35--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-12-24 16:10:36 (106 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "94c368ac-cce7-4a82-d7fa-2f79ae6dfa56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "c33c7f32-7b38-4bf0-e2ee-019ada55e1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "4aa835b2-b8fd-45f5-f884-922f87262c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "100/100 - 31s - loss: 0.2526 - acc: 0.9027 - val_loss: 7.6911e-04 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0761 - acc: 0.9713 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0474 - acc: 0.9842 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0462 - acc: 0.9833 - val_loss: 0.0017 - val_acc: 1.0000\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0426 - acc: 0.9873 - val_loss: 0.1177 - val_acc: 0.9717\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0502 - acc: 0.9839 - val_loss: 0.1508 - val_acc: 0.9717\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0292 - acc: 0.9909 - val_loss: 0.1812 - val_acc: 0.9676\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0257 - acc: 0.9929 - val_loss: 0.2742 - val_acc: 0.9555\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0404 - acc: 0.9863 - val_loss: 0.4968 - val_acc: 0.9413\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0425 - acc: 0.9883 - val_loss: 0.3038 - val_acc: 0.9534\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0238 - acc: 0.9919 - val_loss: 0.1820 - val_acc: 0.9798\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0157 - acc: 0.9939 - val_loss: 0.0686 - val_acc: 0.9879\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0281 - acc: 0.9889 - val_loss: 0.4023 - val_acc: 0.9565\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0187 - acc: 0.9944 - val_loss: 0.3937 - val_acc: 0.9605\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0244 - acc: 0.9924 - val_loss: 0.4215 - val_acc: 0.9575\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0360 - acc: 0.9909 - val_loss: 0.5799 - val_acc: 0.9443\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0159 - acc: 0.9949 - val_loss: 0.6224 - val_acc: 0.9433\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0201 - acc: 0.9940 - val_loss: 0.8153 - val_acc: 0.9453\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0203 - acc: 0.9929 - val_loss: 0.3988 - val_acc: 0.9646\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0136 - acc: 0.9960 - val_loss: 0.3525 - val_acc: 0.9727\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0183 - acc: 0.9944 - val_loss: 0.7784 - val_acc: 0.9413\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0307 - acc: 0.9904 - val_loss: 0.2836 - val_acc: 0.9777\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0131 - acc: 0.9970 - val_loss: 0.4927 - val_acc: 0.9615\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0407 - acc: 0.9929 - val_loss: 0.5725 - val_acc: 0.9545\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0151 - acc: 0.9954 - val_loss: 0.7848 - val_acc: 0.9484\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0158 - acc: 0.9934 - val_loss: 0.8094 - val_acc: 0.9474\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0105 - acc: 0.9970 - val_loss: 1.0846 - val_acc: 0.9413\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0136 - acc: 0.9965 - val_loss: 1.7898 - val_acc: 0.9119\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0385 - acc: 0.9950 - val_loss: 1.0492 - val_acc: 0.9443\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0169 - acc: 0.9929 - val_loss: 0.8936 - val_acc: 0.9484\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0164 - acc: 0.9970 - val_loss: 0.4865 - val_acc: 0.9615\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0141 - acc: 0.9964 - val_loss: 0.7712 - val_acc: 0.9474\n",
            "Epoch 33/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0106 - acc: 0.9959 - val_loss: 0.7225 - val_acc: 0.9514\n",
            "Epoch 34/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0147 - acc: 0.9965 - val_loss: 1.4119 - val_acc: 0.9312\n",
            "Epoch 35/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0082 - acc: 0.9975 - val_loss: 1.2720 - val_acc: 0.9352\n",
            "Epoch 36/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0231 - acc: 0.9965 - val_loss: 1.1196 - val_acc: 0.9413\n",
            "Epoch 37/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0063 - acc: 0.9975 - val_loss: 1.1086 - val_acc: 0.9393\n",
            "Epoch 38/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0131 - acc: 0.9965 - val_loss: 0.9492 - val_acc: 0.9474\n",
            "Epoch 39/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0081 - acc: 0.9975 - val_loss: 1.0047 - val_acc: 0.9413\n",
            "Epoch 40/100\n",
            "Epoch 1/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 21s - loss: 0.0067 - acc: 0.9995 - val_loss: 1.4876 - val_acc: 0.9393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "c6635ecd-e843-4936-af53-03bc9c3a1a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlgTHCr3FYrEkOP8Pttj7qQRjyy4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3QFy3kepBUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}